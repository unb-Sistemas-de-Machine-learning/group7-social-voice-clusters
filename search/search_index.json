{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sobre","text":"<p> Vozes em Rede \u00e9 uma solu\u00e7\u00e3o inovadora que transforma manifesta\u00e7\u00f5es p\u00fablicas em conhecimento estruturado para apoiar gestores p\u00fablicos na tomada de decis\u00e3o baseada em evid\u00eancias. Utilizando t\u00e9cnicas de machine learning para clusteriza\u00e7\u00e3o sem\u00e2ntica, o sistema agrupa manifesta\u00e7\u00f5es em temas recorrentes, identifica padr\u00f5es e apresenta insights de forma visual e acess\u00edvel.   </p> Objetivos do Projeto <ul> <li>Coletar manifesta\u00e7\u00f5es p\u00fablicas de m\u00faltiplas fontes de forma automatizada e peri\u00f3dica.</li> <li>Normalizar, limpar e padronizar os textos coletados para garantir qualidade anal\u00edtica.</li> <li>Agrupar manifesta\u00e7\u00f5es em clusters tem\u00e1ticos, facilitando a identifica\u00e7\u00e3o de demandas sociais.</li> <li>Proporcionar uma interface intuitiva, acess\u00edvel e responsiva para gestores e analistas.</li> </ul>  Equipe  Jo\u00e3o Victor Cruz Miguel Arthur Rafael Bosi"},{"location":"engenharia_de_dados/amostragem_e_rotulacao/","title":"Amostragem e Rotula\u00e7\u00e3o","text":""},{"location":"engenharia_de_dados/amostragem_e_rotulacao/#amostragem","title":"Amostragem","text":"<p>Devido ao escopo do projeto (conjunto enxuto de 100\u2013300 manifesta\u00e7\u00f5es), adotamos a amostragem por conveni\u00eancia com enfoque em curadoria e diversidade tem\u00e1tica.</p> <p>Essas medidas maximizam o valor informativo mesmo com poucos exemplos e permitem uma avalia\u00e7\u00e3o significativa da interpretabilidade dos clusters.</p>"},{"location":"engenharia_de_dados/amostragem_e_rotulacao/#rotulacao","title":"Rotula\u00e7\u00e3o","text":"<p>N\u00e3o foi necess\u00e1rio realizar rotula\u00e7\u00e3o manual dos dados, pois o problema abordado \u00e9 de clusteriza\u00e7\u00e3o de textos, uma tarefa de aprendizado de m\u00e1quina n\u00e3o-supervisionada. O pr\u00f3prio algoritmo (como K-Means ou DBSCAN) \u00e9 respons\u00e1vel por identificar grupos de manifesta\u00e7\u00f5es semelhantes, sem a necessidade de r\u00f3tulos pr\u00e9vios. Isso simplifica o pipeline e reduz o esfor\u00e7o de prepara\u00e7\u00e3o dos dados.</p>"},{"location":"engenharia_de_dados/amostragem_e_rotulacao/#balanceamento-de-classes","title":"Balanceamento de Classes","text":"<p>O conceito de balanceamento de classes n\u00e3o se aplica neste projeto, j\u00e1 que n\u00e3o h\u00e1 classes ou r\u00f3tulos definidos previamente. O objetivo \u00e9 justamente descobrir agrupamentos naturais nos dados, sem impor categorias artificiais. Caso, ap\u00f3s a clusteriza\u00e7\u00e3o, seja identificada uma grande disparidade no tamanho dos clusters, isso ser\u00e1 analisado como um resultado do pr\u00f3prio fen\u00f4meno social e n\u00e3o como um problema de modelagem.</p>"},{"location":"engenharia_de_dados/coleta_e_armazenamento/","title":"Coleta e Armazenamento de Dados","text":"<p>A coleta de dados \u00e9 uma etapa fundamental para garantir a qualidade e a representatividade das manifesta\u00e7\u00f5es analisadas pelo modelo de clusteriza\u00e7\u00e3o. Como a API do Fala.Br n\u00e3o est\u00e1 dispon\u00edvel para acesso imediato, optamos por uma estrat\u00e9gia de coleta automatizada, utilizando t\u00e9cnicas de web scraping para extrair dados textuais de fontes p\u00fablicas relevantes.</p> <p>O processo \u00e9 realizado de forma automatizada, com scrapers Python que acessam sites de not\u00edcias, f\u00f3runs e canais de redes sociais. Cada scraper envia os registros coletados para o servi\u00e7o central de ingest\u00e3o via HTTP (<code>POST /ingest</code>) ou \u2014 em cen\u00e1rios offline ou especializados \u2014 escreve diretamente no MongoDB usando <code>pymongo</code>.</p> <p>Observa\u00e7\u00e3o importante sobre volume: este projeto N\u00c3O pretende coletar grandes massas de dados. O objetivo \u00e9 obter um conjunto enxuto e de qualidade, entre 100 e 300 manifesta\u00e7\u00f5es, e construir um modelo eficiente e interpret\u00e1vel a partir desse volume. </p>"},{"location":"engenharia_de_dados/coleta_e_armazenamento/#armazenamento-e-esquema-pretendido-mongodb","title":"Armazenamento e esquema pretendido (MongoDB)","text":"<ul> <li>Banco: <code>vozes_em_rede</code></li> <li> <p>Cole\u00e7\u00e3o <code>raw_manifestacoes</code> \u2014 documentos brutos recebidos da coleta. Campos pretendidos:</p> <ul> <li><code>_id</code> (ObjectId)</li> <li><code>texto</code> (string)</li> <li><code>fonte</code> (string)</li> <li><code>url</code> (string)</li> <li><code>id_origem</code> (string)</li> <li><code>metadata</code> (object)</li> <li><code>timestamp_coleta</code> (datetime)</li> <li><code>status</code> (string) \u2014 ex.: <code>raw</code>, <code>processing</code>, <code>processed</code>, <code>error</code></li> </ul> </li> <li> <p>Cole\u00e7\u00e3o <code>processed_manifestacoes</code> \u2014 documentos resultantes do pr\u00e9-processamento e enriquecimento. Campos pretendidos:</p> <ul> <li><code>raw_id</code> (ObjectId) \u2014 refer\u00eancia ao documento em <code>raw_manifestacoes</code></li> <li><code>texto</code> (string) \u2014 vers\u00e3o limpa/normalizada</li> <li><code>embedding</code> (array[float] ou refer\u00eancia para vector-db)</li> <li><code>sentiment</code> (string) \u2014 opcional</li> <li><code>topic_tags</code> (array[string]) \u2014 opcional, a partir de heur\u00edsticas</li> <li><code>status</code> (string)</li> </ul> </li> </ul> <p>Essa organiza\u00e7\u00e3o separa claramente a fonte original (<code>raw_manifestacoes</code>) do dado pronto para modelagem (<code>processed_manifestacoes</code>), facilitando reprocessamentos e auditoria.</p>"},{"location":"engenharia_de_dados/coleta_e_armazenamento/#fontes-de-dados-para-web-scraping","title":"Fontes de Dados para Web Scraping","text":"<p>Para a nossa estrat\u00e9gia de web scraping, focaremos nas seguintes fontes:</p> <ul> <li>Reclame Aqui: Uma fonte rica em textos de reclama\u00e7\u00f5es que, apesar de focar no setor privado, possui uma estrutura e um vocabul\u00e1rio semelhantes \u00e0s manifesta\u00e7\u00f5es de ouvidoria.</li> <li>F\u00f3runs e Comunidades Online: Plataformas onde cidad\u00e3os discutem problemas urbanos e servi\u00e7os p\u00fablicos.</li> <li>Canais Governamentais em Redes Sociais: Coment\u00e1rios em postagens de \u00f3rg\u00e3os p\u00fablicos em plataformas como o Instagram e o Twitter (X).</li> </ul>"},{"location":"engenharia_de_dados/dados_treinamento_teste/","title":"Dados de Treinamento e Teste","text":"<p>Para garantir a avalia\u00e7\u00e3o adequada do modelo de clusteriza\u00e7\u00e3o, o conjunto de dados coletado ser\u00e1 dividido em dois subconjuntos principais:</p> <ul> <li> <p>Holdout temporal / simula\u00e7\u00e3o de streaming:como os dados ter\u00e3o carimbo temporal, reservaremos ~10\u201320% (ou um per\u00edodo delimitado) como conjunto de teste para simular novos dados em produ\u00e7\u00e3o.</p> </li> <li> <p>Amostra rotulada pequena: criaremos um conjunto rotulado de 80\u2013200 exemplos (dependendo do total dispon\u00edvel) para valida\u00e7\u00e3o extr\u00ednseca \u2014 esse conjunto ser\u00e1 suficiente para NMI/ARI e an\u00e1lises qualitativas.</p> </li> </ul>"},{"location":"engenharia_de_dados/dados_treinamento_teste/#avaliacao-e-metricas-praticas","title":"Avalia\u00e7\u00e3o e m\u00e9tricas pr\u00e1ticas:","text":"<ul> <li>M\u00e9tricas intr\u00ednsecas: Silhouette score e Davies-Bouldin (simples e informativas). Como a base \u00e9 pequena, interpretar essas m\u00e9tricas junto com revis\u00e3o humana.</li> <li>M\u00e9tricas extr\u00ednsecas (com small labeled set): NMI e ARI para medir concord\u00e2ncia entre clusters e r\u00f3tulos humanos.</li> <li>An\u00e1lise qualitativa: revisaremos manualmente o conte\u00fado de 5\u201310 exemplos por cluster para validar interpretabilidade.</li> </ul>"},{"location":"engenharia_de_dados/feature_engineering/","title":"Feature Engineering","text":"<p>O processo de feature engineering \u00e9 fundamental para garantir que o modelo de clusteriza\u00e7\u00e3o trabalhe com dados limpos, relevantes e representativos. A seguir, detalhamos como cada etapa \u00e9 tratada no projeto.</p>"},{"location":"engenharia_de_dados/feature_engineering/#pre-processamento-e-tratamento-de-dados","title":"Pr\u00e9-processamento e Tratamento de Dados","text":"<ul> <li>Missing values: Durante a coleta, entradas com valores nulos ou vazios s\u00e3o automaticamente descartadas. Isso evita que textos incompletos ou inv\u00e1lidos prejudiquem a qualidade do modelo.</li> <li>Outliers: Textos considerados outliers (muito curtos, excessivamente longos ou com caracteres incomuns) s\u00e3o removidos na etapa de pr\u00e9-processamento. Isso garante que apenas manifesta\u00e7\u00f5es genu\u00ednas e informativas sejam analisadas.</li> <li>Enriquecimento dos dados: N\u00e3o realizamos enriquecimento externo (ex: cruzamento com outras bases). O foco est\u00e1 em extrair o m\u00e1ximo de informa\u00e7\u00e3o do pr\u00f3prio texto, aplicando t\u00e9cnicas como tokeniza\u00e7\u00e3o, lematiza\u00e7\u00e3o e remo\u00e7\u00e3o de stopwords para preparar o dado para os embeddings.</li> <li>Excluir vari\u00e1veis in\u00fateis: Apenas o texto principal e metadados essenciais (data, fonte) s\u00e3o mantidos. Informa\u00e7\u00f5es irrelevantes ou redundantes s\u00e3o descartadas antes da modelagem, otimizando o processamento e a mem\u00f3ria.</li> <li>Normaliza\u00e7\u00e3o e padroniza\u00e7\u00e3o: Todo texto \u00e9 convertido para min\u00fasculas, pontua\u00e7\u00f5es e stopwords s\u00e3o removidas, e caracteres especiais s\u00e3o tratados. Isso padroniza a entrada e facilita a compara\u00e7\u00e3o sem\u00e2ntica entre manifesta\u00e7\u00f5es.</li> <li>One Hot Encoding: N\u00e3o utilizamos One Hot Encoding, pois trabalhamos com dados textuais. A representa\u00e7\u00e3o num\u00e9rica dos textos \u00e9 feita por meio de embeddings de texto (ex: BERTimbau), que capturam o significado sem\u00e2ntico das palavras e frases, sendo mais adequados para clusteriza\u00e7\u00e3o.</li> </ul>"},{"location":"engenharia_de_dados/feature_engineering/#embeddings-e-armazenamento","title":"Embeddings e armazenamento","text":"<p>As representa\u00e7\u00f5es num\u00e9ricas dos textos ser\u00e3o geradas via Ollama (modelo <code>nomic-embed-text</code> ou similar) conforme descrito na arquitetura.</p> <ul> <li>Embeddings gerado ap\u00f3s o pr\u00e9-processamento (texto limpo). Salvando o vetor no campo <code>embedding</code> em <code>processed_manifestacoes</code> como <code>array[float]</code> para consultas vetoriais r\u00e1pidas.</li> <li>Formato: listas de floats (JSON) ou armazenamento bin\u00e1rio (parquet/npz) dependendo do volume. Se usado JSON, iremos considerar compress\u00e3o ou armazenamento em base64 para economia de espa\u00e7o.</li> <li>Indexa\u00e7\u00e3o: para realizar buscas por similaridade em tempo real, configuramos um indexador (annoy, faiss, Milvus) ou usar um servi\u00e7o gerenciado. </li> <li>Versionamento: mantemos <code>embedding_version</code> no documento processado para controlar mudan\u00e7as no modelo de embedding.</li> </ul>"},{"location":"engenharia_de_dados/feature_engineering/#data-augmentation","title":"Data Augmentation","text":"<p>N\u00e3o aplicamos t\u00e9cnicas de data augmentation para textos, pois a diversidade natural das manifesta\u00e7\u00f5es coletadas j\u00e1 proporciona varia\u00e7\u00e3o suficiente para o aprendizado do modelo. Caso o volume de dados se mostre insuficiente, poderemos reavaliar essa decis\u00e3o em etapas futuras.</p>"},{"location":"historias_de_usuario/criterios_de_aceitacao/","title":"Introdu\u00e7\u00e3o","text":"<p>Este documento detalha os crit\u00e9rios de aceita\u00e7\u00e3o para cada hist\u00f3ria de usu\u00e1rio do projeto Vozes em Rede, al\u00e9m de apresentar a prioriza\u00e7\u00e3o das funcionalidades utilizando a t\u00e9cnica MoSCoW. Os crit\u00e9rios servem como refer\u00eancia para valida\u00e7\u00e3o e acompanhamento do desenvolvimento do sistema.</p>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#criterios-de-aceitacao","title":"Crit\u00e9rios de Aceita\u00e7\u00e3o","text":""},{"location":"historias_de_usuario/criterios_de_aceitacao/#us01","title":"US01","text":"<ul> <li>O sistema coleta manifesta\u00e7\u00f5es de pelo menos duas fontes distintas.</li> <li>A coleta \u00e9 realizada de forma automatizada e peri\u00f3dica.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us02","title":"US02","text":"<ul> <li>Os textos coletados s\u00e3o padronizados, sem duplicidades ou caracteres especiais.</li> <li>O sistema remove ru\u00eddos e normaliza os dados antes da an\u00e1lise.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us03","title":"US03","text":"<ul> <li>O sistema agrupa manifesta\u00e7\u00f5es em clusters tem\u00e1ticos automaticamente.</li> <li>Os clusters s\u00e3o interpret\u00e1veis e refletem temas recorrentes.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us04","title":"US04","text":"<ul> <li>Cada manifesta\u00e7\u00e3o pode pertencer a mais de um cluster.</li> <li>O grau de pertencimento \u00e9 apresentado de forma clara ao usu\u00e1rio.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us05","title":"US05","text":"<ul> <li>O sistema identifica o sentimento predominante (positivo, negativo, neutro) em cada manifesta\u00e7\u00e3o.</li> <li>O sentimento \u00e9 exibido junto ao tema/cluster correspondente.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us06","title":"US06","text":"<ul> <li>O dashboard apresenta gr\u00e1ficos e mapas interativos dos clusters.</li> <li>O usu\u00e1rio pode filtrar e explorar os dados visualmente.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us07","title":"US07","text":"<ul> <li>O sistema gera relat\u00f3rios customiz\u00e1veis com volume, temas e sentimentos.</li> <li>Os relat\u00f3rios podem ser salvos e compartilhados.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us08","title":"US08","text":"<ul> <li>O usu\u00e1rio pode exportar dados e relat\u00f3rios em PDF e CSV.</li> <li>Os arquivos exportados mant\u00eam a formata\u00e7\u00e3o e integridade dos dados.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us09","title":"US09","text":"<ul> <li>O sistema \u00e9 acess\u00edvel em diferentes dispositivos (desktop, tablet, smartphone).</li> <li>A interface se adapta ao tamanho da tela.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#us10","title":"US10","text":"<ul> <li>O sistema possui interface intuitiva, com navega\u00e7\u00e3o clara.</li> <li>O usu\u00e1rio consegue realizar an\u00e1lises sem treinamento avan\u00e7ado.</li> </ul>"},{"location":"historias_de_usuario/criterios_de_aceitacao/#priorizacao-moscow","title":"Prioriza\u00e7\u00e3o (MoSCoW)","text":"US Descri\u00e7\u00e3o Resumida Prioridade US01 Coleta multicanal de manifesta\u00e7\u00f5es Must US02 Normaliza\u00e7\u00e3o e limpeza de textos Must US03 Clusteriza\u00e7\u00e3o autom\u00e1tica de temas Must US04 Visualiza\u00e7\u00e3o do grau de pertencimento a m\u00faltiplos temas Should US05 An\u00e1lise de sentimento Should US06 Dashboard interativo de clusters Must US07 Gera\u00e7\u00e3o de relat\u00f3rios customiz\u00e1veis Could US08 Exporta\u00e7\u00e3o de dados e relat\u00f3rios Could US09 Acesso multiplataforma Could US10 Interface intuitiva e f\u00e1cil de usar Must"},{"location":"historias_de_usuario/mvp/","title":"MVP (Produto M\u00ednimo Vi\u00e1vel)","text":"<p>O MVP do projeto Vozes em Rede contempla a entrega das funcionalidades essenciais para coleta, clusteriza\u00e7\u00e3o, an\u00e1lise e visualiza\u00e7\u00e3o de manifesta\u00e7\u00f5es p\u00fablicas, priorizando as hist\u00f3rias de usu\u00e1rio classificadas como Must e Should. Funcionalidades Could ser\u00e3o implementadas apenas se houver tempo dispon\u00edvel, enquanto Won't ficam reservadas para incrementos futuros.</p>"},{"location":"historias_de_usuario/mvp/#us-contempladas-no-mvp","title":"US contempladas no MVP","text":"<p>Must (Essenciais):</p> <ul> <li>US01: Coleta multicanal de manifesta\u00e7\u00f5es</li> <li>US02: Normaliza\u00e7\u00e3o e limpeza de textos</li> <li>US03: Clusteriza\u00e7\u00e3o autom\u00e1tica de temas</li> <li>US06: Dashboard interativo de clusters</li> <li>US10: Interface intuitiva e f\u00e1cil de usar</li> </ul> <p>Should (Desej\u00e1veis):</p> <ul> <li>US04: Visualiza\u00e7\u00e3o do grau de pertencimento a m\u00faltiplos temas</li> <li>US05: An\u00e1lise de sentimento</li> <li>US07: Gera\u00e7\u00e3o de relat\u00f3rios customiz\u00e1veis</li> </ul> <p>Could (Apenas se houver tempo):</p> <ul> <li>US08: Exporta\u00e7\u00e3o de dados e relat\u00f3rios</li> <li>US09: Acesso multiplataforma</li> </ul>"},{"location":"historias_de_usuario/mvp/#entregas-tecnicas-esperadas-no-mvp","title":"Entregas t\u00e9cnicas esperadas no MVP","text":"<p>Al\u00e9m das hist\u00f3rias de usu\u00e1rio, o MVP deve incluir as seguintes entregas t\u00e9cnicas descritas na arquitetura:</p> <ul> <li>Endpoint de ingest\u00e3o <code>POST /ingest</code> na API (recebe payloads do scraper e persiste no MongoDB).</li> <li>Servi\u00e7o de armazenamento MongoDB com cole\u00e7\u00f5es <code>raw_manifestacoes</code> e <code>processed_manifestacoes</code>.</li> <li>Servi\u00e7o/worker de pr\u00e9-processamento (script que normaliza e marca <code>status: processed</code>).</li> <li>Integra\u00e7\u00e3o com Ollama para gera\u00e7\u00e3o de embeddings (endpoint local do Ollama configurado).</li> <li>Script de treinamento <code>treinar.py</code> e o artefato treinado <code>models/modelo_cluster.joblib</code>.</li> <li>Endpoint <code>POST /clusterizar</code> para obter cluster a partir de texto/embedding.</li> <li>Dashboard b\u00e1sico ou rota de consulta para validar visualmente os clusters.</li> </ul>"},{"location":"historias_de_usuario/mvp/#incrementos-futuramente-planejados","title":"Incrementos Futuramente Planejados","text":"<p>Funcionalidades classificadas como Could e demais melhorias identificadas durante o desenvolvimento poder\u00e3o ser implementadas ap\u00f3s a entrega do MVP, conforme disponibilidade de tempo e recursos.</p>"},{"location":"historias_de_usuario/mvp/#cronograma-de-entregas","title":"Cronograma de Entregas","text":"<p>Per\u00edodo Total: 18/08/2025 a 03/12/2025 (16 semanas)</p> Semana Per\u00edodo (In\u00edcio em) Fase do Projeto Principais Atividades e Entreg\u00e1veis Status 1-7 18/08 a 29/09 Fase 1: Concep\u00e7\u00e3o e Documenta\u00e7\u00e3o - Defini\u00e7\u00e3o do problema e escopo inicial.- Cria\u00e7\u00e3o dos artefatos: Fishbone, Idea Canva, Parking Lot, Idea Filter, ML Canvas.- Levantamento e documenta\u00e7\u00e3o dos Requisitos (Produto e ML).- Elabora\u00e7\u00e3o das Hist\u00f3rias de Usu\u00e1rio e Backlog do Produto. Conclu\u00eddo 8-9 29/09 a 20/10 - Desenvolvimento do script de coleta de dados (web scraping e APIs p\u00fablicas).- Refinamento do Backlog e do planejamento.- Cria\u00e7\u00e3o inicial da base de dados.- Apresenta\u00e7\u00e3o do ponto de controle TF-1. Em Andamento 10 20/10 a 27/10 Fase 2: Desenvolvimento (Sprint 1 - Core de Clusteriza\u00e7\u00e3o) - Implementa\u00e7\u00e3o do pipeline de processamento e clusteriza\u00e7\u00e3o de dados.- Implementa\u00e7\u00e3o das US01, US02 e US03.- Testes unit\u00e1rios e integra\u00e7\u00e3o do pipeline. Planejado 11 27/10 a 03/11 - Implementa\u00e7\u00e3o do dashboard interativo (US06).- Testes de visualiza\u00e7\u00e3o e usabilidade.- Ajustes na interface (US10). Planejado 12 03/11 a 10/11 Fase 2: Desenvolvimento (Sprint 2 - Funcionalidades Avan\u00e7adas) - Implementa\u00e7\u00e3o das US Should: US04, US05, US07.- Testes de integra\u00e7\u00e3o e valida\u00e7\u00e3o das funcionalidades.- Refino dos dashboards e relat\u00f3rios. Planejado 13 10/11 a 17/11 - Continua\u00e7\u00e3o do Sprint 2.- Corre\u00e7\u00e3o de bugs e ajustes de performance.- Testes ponta-a-ponta (E2E). Planejado 14 17/11 a 24/11 Fase 3: Testes e Refinamento - Testes finais de usabilidade e desempenho.- Garantir atendimento aos requisitos RNF.- Prepara\u00e7\u00e3o da documenta\u00e7\u00e3o final. Planejado 15 24/11 a 01/12 Fase 4: Lan\u00e7amento - Deploy do MVP em ambiente de produ\u00e7\u00e3o/homologa\u00e7\u00e3o.- Treinamento r\u00e1pido para usu\u00e1rios-chave. Planejado 16 01/12 a 03/12 Fase 5: APRESENTA\u00c7\u00c3O FINAL DO PRODUTO - Apresenta\u00e7\u00e3o do produto desenvolvido ao longo do semestre.- Entrega dos artefatos finais. Planejado"},{"location":"historias_de_usuario/us_list/","title":"Hist\u00f3rias de Usu\u00e1rio","text":""},{"location":"historias_de_usuario/us_list/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este documento apresenta as hist\u00f3rias de usu\u00e1rio do projeto Vozes em Rede, organizadas em \u00e9picos. Cada hist\u00f3ria descreve, do ponto de vista do usu\u00e1rio, as principais funcionalidades e necessidades do sistema, servindo de base para o desenvolvimento e valida\u00e7\u00e3o do produto.</p>"},{"location":"historias_de_usuario/us_list/#epico-1-coleta-e-preparacao-de-dados","title":"\u00c9pico 1: Coleta e Prepara\u00e7\u00e3o de Dados","text":"<p>US01 Como gestor p\u00fablico, eu quero que o sistema colete manifesta\u00e7\u00f5es de diferentes fontes (redes sociais, sites de not\u00edcias, canais institucionais), para que eu tenha uma base de dados ampla e atualizada para an\u00e1lise.</p> <p>Requisitos Relacionados: RF01, RMF03</p> <p>US02 Como analista de dados, eu quero que o sistema normalize e limpe os textos coletados, para garantir que as an\u00e1lises sejam feitas sobre dados padronizados e sem ru\u00eddos.</p> <p>Requisitos Relacionados: RF02, RMF03</p>"},{"location":"historias_de_usuario/us_list/#epico-2-clusterizacao-e-analise-tematica","title":"\u00c9pico 2: Clusteriza\u00e7\u00e3o e An\u00e1lise Tem\u00e1tica","text":"<p>US03 Como gestor p\u00fablico, eu quero que o sistema agrupe manifesta\u00e7\u00f5es em clusters tem\u00e1ticos automaticamente, para identificar padr\u00f5es e temas recorrentes nas demandas da popula\u00e7\u00e3o.</p> <p>Requisitos Relacionados: RF05, RMF01, RMF02, RMF04, RMF05</p> <p>US04 Como analista de dados, eu quero visualizar o grau de pertencimento de cada manifesta\u00e7\u00e3o a m\u00faltiplos clusters, para compreender a complexidade e a sobreposi\u00e7\u00e3o de temas em cada mensagem.</p> <p>Requisitos Relacionados: RMF02, RMF05</p> <p>US05 Como gestor p\u00fablico, eu quero que o sistema identifique e rotule o sentimento predominante em cada manifesta\u00e7\u00e3o, para avaliar o tom geral das demandas e opini\u00f5es recebidas.</p> <p>Requisitos Relacionados: RF04</p>"},{"location":"historias_de_usuario/us_list/#epico-3-visualizacao-e-relatorios","title":"\u00c9pico 3: Visualiza\u00e7\u00e3o e Relat\u00f3rios","text":"<p>US06 Como gestor p\u00fablico, eu quero acessar dashboards interativos com gr\u00e1ficos e mapas dos clusters formados, para acompanhar tend\u00eancias e tomar decis\u00f5es baseadas em evid\u00eancias.</p> <p>Requisitos Relacionados: RF06, RMF05, RNF04</p> <p>US07 Como gestor p\u00fablico, eu quero gerar relat\u00f3rios customiz\u00e1veis sobre volume, temas e sentimentos das manifesta\u00e7\u00f5es, para compartilhar an\u00e1lises com outros setores e apoiar a formula\u00e7\u00e3o de pol\u00edticas.</p> <p>Requisitos Relacionados: RF07</p> <p>US08 Como gestor p\u00fablico, eu quero exportar os dados e relat\u00f3rios em formatos como PDF e CSV, para facilitar o armazenamento e o compartilhamento das informa\u00e7\u00f5es.</p> <p>Requisitos Relacionados: RF08</p>"},{"location":"historias_de_usuario/us_list/#epico-4-acesso-e-usabilidade","title":"\u00c9pico 4: Acesso e Usabilidade","text":"<p>US09 Como gestor p\u00fablico, eu quero acessar o sistema de diferentes dispositivos, para poder acompanhar as an\u00e1lises mesmo fora do ambiente de trabalho.</p> <p>Requisitos Relacionados: RNF04, RNF08</p> <p>US10 Como analista de dados, eu quero que o sistema seja intuitivo e f\u00e1cil de usar, para que eu possa realizar an\u00e1lises sem necessidade de treinamento avan\u00e7ado.</p> <p>Requisitos Relacionados: RNF04, RNF06</p>"},{"location":"ml/ml_canvas/","title":"ML Canvas","text":""},{"location":"ml/ml_canvas/#descricao-da-ferramenta","title":"Descri\u00e7\u00e3o da Ferramenta","text":"<p>O ML Canvas \u00e9 uma ferramenta visual para planejamento e comunica\u00e7\u00e3o de projetos de machine learning. Ele permite mapear, de forma estruturada, as tarefas de previs\u00e3o, decis\u00f5es, fontes e coleta de dados, constru\u00e7\u00e3o de modelos, m\u00e9tricas e demais aspectos essenciais para o sucesso do projeto.</p>"},{"location":"ml/ml_canvas/#aplicacao-no-projeto","title":"Aplica\u00e7\u00e3o no Projeto","text":"<p>No Vozes em Rede, o ML Canvas foi utilizado para organizar e alinhar as etapas do desenvolvimento do modelo de clusteriza\u00e7\u00e3o sem\u00e2ntica. Inicialmente, a coleta de dados seria feita via API do FalaBR, mas devido a obst\u00e1culos de acesso, a estrat\u00e9gia foi adaptada para utilizar dados de sites de not\u00edcias e redes sociais, garantindo a viabilidade do projeto no prazo dispon\u00edvel.</p>"},{"location":"ml/ml_canvas/#principais-insights","title":"Principais Insights","text":"<ul> <li>O foco do modelo \u00e9 a clusteriza\u00e7\u00e3o de manifesta\u00e7\u00f5es, sem previs\u00e3o tradicional.</li> <li>As classifica\u00e7\u00f5es s\u00e3o apresentadas ao usu\u00e1rio via dashboards tem\u00e1ticos.</li> <li>A coleta e armazenamento dos dados foram adaptados para fontes p\u00fablicas acess\u00edveis.</li> <li>O modelo ser\u00e1 avaliado por m\u00e9tricas como F1-score, com revalida\u00e7\u00e3o caso a acur\u00e1cia caia abaixo de 80%.</li> <li>O uso de texto bruto como entrada e a aus\u00eancia de necessidade de atualiza\u00e7\u00e3o em tempo real simplificam o pipeline.</li> </ul> <p>Figura 1: ML Canva detalhando o fluxo e decis\u00f5es do modelo de clusteriza\u00e7\u00e3o do Vozes em Rede.</p>"},{"location":"ml/requisitos_de_ml/","title":"Requisitos de Machine Learning","text":""},{"location":"ml/requisitos_de_ml/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Esta se\u00e7\u00e3o apresenta os requisitos funcionais e n\u00e3o funcionais do(s) modelo(s) de machine learning do projeto Vozes em Rede, com base no planejamento realizado no ML Canva. O foco \u00e9 garantir entreg\u00e1veis vi\u00e1veis, priorizando a clusteriza\u00e7\u00e3o de manifesta\u00e7\u00f5es p\u00fablicas e a gera\u00e7\u00e3o de insights tem\u00e1ticos para gestores.</p>"},{"location":"ml/requisitos_de_ml/#requisitos-funcionais","title":"Requisitos Funcionais","text":"C\u00f3digo Nome do Requisito Descri\u00e7\u00e3o RMF01 Clusteriza\u00e7\u00e3o Sem\u00e2ntica O modelo deve agrupar manifesta\u00e7\u00f5es p\u00fablicas em clusters tem\u00e1ticos de acordo com similaridade textual. RMF02 Classifica\u00e7\u00e3o Multitem\u00e1tica Cada manifesta\u00e7\u00e3o pode pertencer a m\u00faltiplos clusters, com indica\u00e7\u00e3o do grau de pertencimento. RMF03 Processamento de Texto Bruto O pipeline deve aceitar textos brutos como entrada, realizando pr\u00e9-processamento b\u00e1sico. RMF04 Avalia\u00e7\u00e3o Peri\u00f3dica do Modelo O modelo deve ser reavaliado periodicamente e refeito caso a acur\u00e1cia caia abaixo de 80%. RMF05 Gera\u00e7\u00e3o de Dashboards de Clusters Os resultados da clusteriza\u00e7\u00e3o devem ser apresentados em dashboards interativos para o usu\u00e1rio. RMF06 Simula\u00e7\u00e3o de Impacto O sistema deve permitir simular crit\u00e9rios de aceita\u00e7\u00e3o/veracidade usando modelos auxiliares."},{"location":"ml/requisitos_de_ml/#requisitos-nao-funcionais","title":"Requisitos N\u00e3o Funcionais","text":"C\u00f3digo Nome do Requisito Descri\u00e7\u00e3o RMNF01 Tempo de Processamento O pipeline de clusteriza\u00e7\u00e3o deve processar lotes de dados em at\u00e9 5 minutos. RMNF02 Modularidade O c\u00f3digo do pipeline deve ser modular, facilitando ajustes e reuso de componentes. RMNF03 Explicabilidade O sistema deve fornecer informa\u00e7\u00f5es sobre os crit\u00e9rios usados para agrupar manifesta\u00e7\u00f5es. RMNF04 Reprodutibilidade Os experimentos de clusteriza\u00e7\u00e3o devem ser reprodut\u00edveis, com controle de vers\u00f5es e random seeds. RMNF05 Portabilidade O pipeline deve ser execut\u00e1vel em ambiente local ou nuvem, sem depend\u00eancias propriet\u00e1rias."},{"location":"ml/requisitos_de_ml/#metricas-de-sucesso","title":"M\u00e9tricas de Sucesso","text":"<ul> <li>F1-score: O modelo deve atingir F1-score m\u00ednimo de 0,80 na avalia\u00e7\u00e3o de agrupamento tem\u00e1tico.</li> <li>Acur\u00e1cia de Clusteriza\u00e7\u00e3o: A taxa de acerto do modelo (valida\u00e7\u00e3o manual ou por modelo auxiliar) deve ser superior a 80%.</li> <li>Cobertura Tem\u00e1tica: O modelo deve identificar pelo menos 80% dos temas relevantes presentes no conjunto de dados.</li> </ul>"},{"location":"produto/arquitetura/","title":"Arquitetura da Solu\u00e7\u00e3o \u2014 Vozes em Rede","text":""},{"location":"produto/arquitetura/#visao-geral","title":"Vis\u00e3o geral","text":"<p>Esta arquitetura foi projetada para rodar localmente no Mac Studio da equipe, usando ferramentas open-source e de baixo custo operacional. A solu\u00e7\u00e3o \u00e9 composta por dois servi\u00e7os principais:</p> <ul> <li>Servi\u00e7o 1 \u2014 Ollama (modelo de embeddings) \u2014 roda nativamente no macOS.</li> <li>Servi\u00e7o 2 \u2014 API de Clusteriza\u00e7\u00e3o (FastAPI) \u2014 roda dentro de um container Docker e consome o Ollama para gerar embeddings.</li> </ul>"},{"location":"produto/arquitetura/#motivacao","title":"Motiva\u00e7\u00e3o","text":"<p>Rodar a pipeline localmente no Mac Studio permite aproveitamento do poder computacional (Apple Silicon), simplicidade operacional e controle total dos dados, reduzindo custos com nuvem durante a fase de desenvolvimento e POC.</p>"},{"location":"produto/arquitetura/#componentes-principais","title":"Componentes Principais","text":"<ul> <li> <p>Ollama (servi\u00e7o de embeddings)</p> <ul> <li>Modelo: <code>nomic-embed-text</code> (ou similar).</li> <li>Exp\u00f5e API local em <code>http://localhost:11434</code>.</li> <li>Roda como aplicativo nativo no macOS (barra de menus).</li> </ul> </li> <li> <p>API de Clusteriza\u00e7\u00e3o</p> <ul> <li>Framework: FastAPI + Uvicorn.</li> <li>Executa dentro de um container Docker.</li> <li>Expondo endpoint: <code>POST /clusterizar</code>.</li> <li>Consome embeddings do Ollama e usa o modelo treinado (<code>modelo_cluster.joblib</code>) para prever clusters.</li> </ul> </li> <li> <p>Banco de Dados</p> <ul> <li>MongoDB (local ou docker) para armazenar manifesta\u00e7\u00f5es brutas, metadados e resultados.</li> <li>Alternativa leve: um diret\u00f3rio com arquivos JSON/CSV para projetos POC.</li> </ul> </li> <li> <p>Scripts de Treinamento</p> <ul> <li>Python scripts que geram embeddings, treinam o clusterizador e salvam o modelo com <code>joblib</code>.</li> </ul> </li> </ul>"},{"location":"produto/arquitetura/#fluxo-de-dados","title":"Fluxo de Dados","text":"<p>Este projeto adota um fluxo de dados linear e expl\u00edcito, do scrapping at\u00e9 o consumo pela aplica\u00e7\u00e3o (1 \u2192 7). Cada etapa descreve entradas, sa\u00eddas e pontos de integra\u00e7\u00e3o.</p> <ul> <li> <p>1 - Coleta (Scraper)</p> <ul> <li>Origem: sites p\u00fablicos, f\u00f3runs, canais de atendimento (ex.: Reclame A\u00ed, redes sociais, formul\u00e1rios p\u00fablicos).</li> <li>Sa\u00edda: documentos brutos (JSON) com metadados (timestamp, url, fonte, id_origem).</li> <li>Modo de entrega: duas op\u00e7\u00f5es (ainda n\u00e3o definido):<ul> <li>Push direto ao MongoDB via biblioteca (pymongo).</li> <li>Push para um endpoint de ingest\u00e3o HTTP (FastAPI) que valida e escreve no MongoDB.</li> </ul> </li> </ul> </li> <li> <p>2 - Armazenamento inicial (MongoDB)</p> <ul> <li>Banco: cole\u00e7\u00e3o <code>raw_manifestacoes</code> contendo o documento bruto e metadados.</li> <li>Cada documento recebe um campo <code>status</code> inicial (ex.: <code>\"status\": \"raw\"</code>) e um <code>_id</code> gerado pelo MongoDB.</li> </ul> </li> <li> <p>3 - Pr\u00e9-processamento (batch ou streaming)</p> <ul> <li>Job local ou cron (script Python) que l\u00ea documentos <code>status: raw</code> da cole\u00e7\u00e3o, aplica limpeza, normaliza\u00e7\u00e3o, extra\u00e7\u00e3o de campos e atualiza/insere em <code>processed_manifestacoes</code> com <code>status: processed</code>.</li> <li>Mant\u00e9m rastreabilidade: campo <code>raw_id</code> que referencia o documento original.</li> </ul> </li> <li> <p>4 - Gera\u00e7\u00e3o de embeddings (Ollama)</p> <ul> <li>Servi\u00e7o Ollama recebe trechos de texto do documento processado e responde com vetores (float array).</li> <li>Embeddings s\u00e3o salvos em MongoDB (ex.: campo <code>embedding</code> no documento processado) ou em servi\u00e7o de vector-db, conforme necessidade.</li> </ul> </li> <li> <p>5 - Treinamento do clusterizador (batch)</p> <ul> <li>Script <code>treinar.py</code> carrega embeddings, treina clusterizador (HDBSCAN / KMeans) e grava <code>models/modelo_cluster.joblib</code>.</li> </ul> </li> <li> <p>6 - Deploy da API de clusteriza\u00e7\u00e3o (FastAPI)</p> <ul> <li> <p>Container Docker que exp\u00f5e endpoints:</p> <ul> <li><code>POST /clusterizar</code> \u2014 recebe texto, obt\u00e9m embedding (Ollama) e retorna cluster e metadados.</li> <li><code>GET /modelo/status</code> \u2014 vers\u00e3o do modelo e data do treino.</li> </ul> </li> <li> <p>Tamb\u00e9m queremos incluir a API o endpoint <code>POST /ingest</code> para receber dados do scraper.</p> </li> </ul> </li> <li> <p>7 - Consumo pela aplica\u00e7\u00e3o / Dashboards</p> <ul> <li>Dashboards, ferramentas de BI ou front-ends fazem chamadas \u00e0 API (<code>/clusterizar</code> ou endpoints de consulta) para obter agrupamentos, m\u00e9tricas e visualiza\u00e7\u00f5es.</li> </ul> </li> </ul>"},{"location":"produto/arquitetura/#fluxograma","title":"Fluxograma","text":"<p>O diagrama abaixo resume do scrapping ao consumo pela aplica\u00e7\u00e3o:</p> <pre><code>  flowchart TD\n        A[\"Scraper\"] --&gt; X[\"API /ingest\"]\n        X --&gt; B(\"MongoDB: raw_manifestacoes\")\n        B --&gt; C(\"Pre-processador (script)\")\n    C --&gt; D(\"MongoDB: processed_manifestacoes\")\n    D --&gt; E[\"Ollama (embeddings)\"]\n    E --&gt; F(\"embeddings armazenados\")\n    F --&gt; G(\"Treinar clusterizador (treinar.py)\")\n    G --&gt; H(\"modelo_cluster.joblib\")\n    H --&gt; I(\"API Docker (FastAPI)\")\n    I --&gt; J(\"Aplica\u00e7\u00e3o / Dashboard (consumo via API)\")</code></pre>"},{"location":"produto/mapeamento_de_dados/","title":"Mapeamento de dados","text":"<p>Objetivo: Apresentar o mapeamento de dados e r\u00f3tulos utilizados no projeto.</p>"},{"location":"produto/mapeamento_de_dados/#mapeamento-de-dados","title":"Mapeamento de Dados","text":""},{"location":"produto/mapeamento_de_dados/#tabela-de-mapeamento","title":"Tabela de Mapeamento","text":""},{"location":"produto/requisitos_do_produto/","title":"Requisitos do Produto","text":""},{"location":"produto/requisitos_do_produto/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este documento apresenta os requisitos funcionais e n\u00e3o funcionais do projeto Vozes em Rede, detalhando as capacidades essenciais e as restri\u00e7\u00f5es t\u00e9cnicas que orientam o desenvolvimento do sistema. Os requisitos foram definidos com base na vis\u00e3o do produto e nas necessidades identificadas para apoiar gestores p\u00fablicos na an\u00e1lise de manifesta\u00e7\u00f5es cidad\u00e3s por meio de clusteriza\u00e7\u00e3o e an\u00e1lise automatizada de dados.</p>"},{"location":"produto/requisitos_do_produto/#requisitos-funcionais","title":"Requisitos Funcionais","text":"C\u00f3digo Nome do Requisito Descri\u00e7\u00e3o RF01 Coleta Multicanal O sistema deve coletar manifesta\u00e7\u00f5es p\u00fablicas de m\u00faltiplas fontes, incluindo redes sociais, sites de not\u00edcias e canais institucionais. RF02 Normaliza\u00e7\u00e3o de Texto O sistema deve limpar e padronizar o conte\u00fado textual coletado, removendo ru\u00eddos, duplicidades e caracteres especiais. RF03 Classifica\u00e7\u00e3o Autom\u00e1tica O modelo deve classificar manifesta\u00e7\u00f5es em categorias tem\u00e1ticas predefinidas. RF04 An\u00e1lise de Sentimento Deve identificar e rotular o sentimento predominante em cada manifesta\u00e7\u00e3o (positivo, negativo ou neutro). RF05 Clusteriza\u00e7\u00e3o de T\u00f3picos O sistema deve agrupar manifesta\u00e7\u00f5es semelhantes por meio de algoritmos de clusteriza\u00e7\u00e3o. RF06 Dashboard Interativo de Clusters O sistema deve apresentar dados e tend\u00eancias de clusteriza\u00e7\u00e3o por meio de gr\u00e1ficos, mapas e filtros interativos. RF07 Gera\u00e7\u00e3o de Relat\u00f3rios Deve gerar relat\u00f3rios customiz\u00e1veis contendo volume, temas e emo\u00e7\u00f5es predominantes. RF08 Exporta\u00e7\u00e3o de Dados Deve permitir exportar resultados e relat\u00f3rios em formatos como PDF e CSV. RF09 Chatbot Integrado O sistema deve disponibilizar um chatbot para consulta r\u00e1pida via Telegram ou interface web."},{"location":"produto/requisitos_do_produto/#requisitos-nao-funcionais","title":"Requisitos N\u00e3o Funcionais","text":"C\u00f3digo Nome do Requisito Descri\u00e7\u00e3o RNF01 Desempenho O sistema deve processar e exibir resultados de consultas em at\u00e9 5 segundos. RNF02 Escalabilidade Deve suportar aumento progressivo de fontes e volume de dados sem perda de desempenho. RNF03 Conformidade com LGPD O sistema deve anonimizar informa\u00e7\u00f5es pessoais e garantir conformidade com a LGPD. RNF04 Usabilidade A interface deve ser intuitiva, responsiva e acess\u00edvel em m\u00faltiplos dispositivos. RNF05 Disponibilidade O sistema deve estar dispon\u00edvel pelo menos 99% do tempo mensal. RNF06 Manutenibilidade O c\u00f3digo deve seguir boas pr\u00e1ticas de modularidade e documenta\u00e7\u00e3o. RNF07 Explicabilidade do Modelo O sistema deve oferecer informa\u00e7\u00f5es sobre os crit\u00e9rios usados pela IA em classifica\u00e7\u00f5es e agrupamentos. RNF08 Portabilidade Deve ser execut\u00e1vel em ambiente de nuvem p\u00fablica ou privada sem depend\u00eancia de hardware espec\u00edfico."},{"location":"produto/visao_do_produto/","title":"Vis\u00e3o do Produto","text":""},{"location":"produto/visao_do_produto/#fishbone","title":"Fishbone","text":""},{"location":"produto/visao_do_produto/#descricao-da-ferramenta","title":"Descri\u00e7\u00e3o da Ferramenta","text":"<p>O Diagrama de Causa e Efeito (Fishbone) \u00e9 uma ferramenta visual utilizada para identificar, organizar e ilustrar as principais causas de um problema central. Ele permite mapear fatores que contribuem para desafios complexos, facilitando a an\u00e1lise sist\u00eamica e a prioriza\u00e7\u00e3o de solu\u00e7\u00f5es.</p>"},{"location":"produto/visao_do_produto/#aplicacao-no-projeto","title":"Aplica\u00e7\u00e3o no Projeto","text":"<p>No contexto do Vozes em Rede, o Fishbone foi empregado para mapear as causas que dificultam a an\u00e1lise eficiente de manifesta\u00e7\u00f5es p\u00fablicas. O principal afetado \u00e9 o gestor p\u00fablico, que enfrenta desafios como o grande volume de dados, a falta de padroniza\u00e7\u00e3o e a ambiguidade das manifesta\u00e7\u00f5es.</p>"},{"location":"produto/visao_do_produto/#principais-insights","title":"Principais Insights","text":"<ul> <li>O principal problema identificado \u00e9 a dificuldade em transformar manifesta\u00e7\u00f5es dispersas e desestruturadas em conhecimento acion\u00e1vel para a tomada de decis\u00e3o baseada em evid\u00eancias.</li> <li>A an\u00e1lise evidenciou a necessidade de mecanismos autom\u00e1ticos de categoriza\u00e7\u00e3o e clusteriza\u00e7\u00e3o para apoiar a gest\u00e3o p\u00fablica.</li> </ul> <p>Figura 1: Diagrama de Causa e Efeito (Fishbone)</p>"},{"location":"produto/visao_do_produto/#idea-canva","title":"Idea Canva","text":""},{"location":"produto/visao_do_produto/#descricao-da-ferramenta_1","title":"Descri\u00e7\u00e3o da Ferramenta","text":"<p>O Idea Canva \u00e9 uma ferramenta de brainstorming visual que permite organizar ideias, funcionalidades e desafios do projeto em diferentes categorias, facilitando a prioriza\u00e7\u00e3o e o alinhamento estrat\u00e9gico.</p>"},{"location":"produto/visao_do_produto/#aplicacao-no-projeto_1","title":"Aplica\u00e7\u00e3o no Projeto","text":"<p>No Vozes em Rede, o Idea Canva foi utilizado para mapear as principais funcionalidades e necessidades do sistema, desde a integra\u00e7\u00e3o de dados at\u00e9 a gera\u00e7\u00e3o de relat\u00f3rios e dashboards interativos.</p>"},{"location":"produto/visao_do_produto/#principais-insights_1","title":"Principais Insights","text":"<ul> <li>Necessidade de integrar dados de canais oficiais do governo e sites de not\u00edcias.</li> <li>Import\u00e2ncia de dashboards interativos, clusteriza\u00e7\u00e3o de temas e alertas autom\u00e1ticos para gestores.</li> <li>Dificuldade central: compreender, organizar e extrair valor das manifesta\u00e7\u00f5es devido ao volume, complexidade e falta de categoriza\u00e7\u00e3o eficiente.</li> </ul> <p>Figura 2: Idea Canva com funcionalidades e desafios mapeados para o Vozes em Rede.</p>"},{"location":"produto/visao_do_produto/#idea-filter-canva","title":"Idea Filter Canva","text":""},{"location":"produto/visao_do_produto/#descricao-da-ferramenta_2","title":"Descri\u00e7\u00e3o da Ferramenta","text":"<p>O Idea Filter Canva \u00e9 uma matriz de prioriza\u00e7\u00e3o que avalia ideias e funcionalidades com base em crit\u00e9rios como confian\u00e7a e relev\u00e2ncia, ajudando a identificar o que deve ser priorizado, mantido ou descartado.</p>"},{"location":"produto/visao_do_produto/#aplicacao-no-projeto_2","title":"Aplica\u00e7\u00e3o no Projeto","text":"<p>No Vozes em Rede, a ferramenta foi usada para filtrar e priorizar ideias levantadas no brainstorming, destacando aquelas com maior potencial de impacto e viabilidade t\u00e9cnica.</p>"},{"location":"produto/visao_do_produto/#principais-insights_2","title":"Principais Insights","text":"<ul> <li>Prioriza\u00e7\u00e3o de dashboards interativos, clusteriza\u00e7\u00e3o de temas e classifica\u00e7\u00e3o por urg\u00eancia.</li> <li>Recomenda\u00e7\u00f5es baseadas em padr\u00f5es detectados e integra\u00e7\u00e3o de dados oficiais tamb\u00e9m foram destacadas.</li> <li>Algumas ideias, como hist\u00f3rico de manifesta\u00e7\u00f5es e relat\u00f3rios export\u00e1veis, foram consideradas menos priorit\u00e1rias.</li> </ul> <p>Figura 3: Idea Filter Canva priorizando funcionalidades para o projeto.</p>"},{"location":"produto/visao_do_produto/#parking-lot-idea-canva","title":"Parking Lot Idea Canva","text":""},{"location":"produto/visao_do_produto/#descricao-da-ferramenta_3","title":"Descri\u00e7\u00e3o da Ferramenta","text":"<p>O Parking Lot Idea Canva \u00e9 um quadro visual para registrar ideias, funcionalidades e requisitos que podem ser explorados futuramente, mas que n\u00e3o s\u00e3o prioridade imediata.</p>"},{"location":"produto/visao_do_produto/#aplicacao-no-projeto_3","title":"Aplica\u00e7\u00e3o no Projeto","text":"<p>No Vozes em Rede, a ferramenta foi utilizada para organizar sugest\u00f5es de features, interface, dados, tecnologia e seguran\u00e7a, servindo como reposit\u00f3rio de inova\u00e7\u00f5es e melhorias para pr\u00f3ximas etapas.</p>"},{"location":"produto/visao_do_produto/#principais-insights_3","title":"Principais Insights","text":"<ul> <li>Destaque para clusteriza\u00e7\u00e3o autom\u00e1tica, dashboards interativos, coleta de dados de m\u00faltiplas fontes e respeito \u00e0 LGPD.</li> <li>Integra\u00e7\u00e3o com APIs p\u00fablicas, explicabilidade do modelo e exporta\u00e7\u00e3o de relat\u00f3rios s\u00e3o pontos de aten\u00e7\u00e3o para o futuro.</li> </ul> <p>Figura 4: Parking Lot Idea Canva com backlog de ideias para o Vozes em Rede.</p>"},{"location":"produto/visao_do_produto/#descricao-do-produto","title":"Descri\u00e7\u00e3o do Produto","text":"<p>O Vozes em Rede surge da necessidade de transformar manifesta\u00e7\u00f5es p\u00fablicas, expressas em diferentes meios e formatos, em conhecimento estruturado que auxilie gestores p\u00fablicos na formula\u00e7\u00e3o de pol\u00edticas e decis\u00f5es baseadas em evid\u00eancias. O projeto tem como n\u00facleo tecnol\u00f3gico um modelo de aprendizado de m\u00e1quina baseado em clusteriza\u00e7\u00e3o sem\u00e2ntica, capaz de agrupar manifesta\u00e7\u00f5es de cidad\u00e3os em temas recorrentes e inter-relacionados.</p> <p>A concep\u00e7\u00e3o do produto partiu da constata\u00e7\u00e3o de que os gestores enfrentam s\u00e9rias dificuldades para compreender o volume, a complexidade e a natureza amb\u00edgua das manifesta\u00e7\u00f5es sociais. Mesmo quando os dados est\u00e3o dispon\u00edveis, a falta de categoriza\u00e7\u00e3o e padroniza\u00e7\u00e3o torna invi\u00e1vel a an\u00e1lise manual. O Vozes em Rede busca resolver esse problema por meio de um sistema que identifica automaticamente padr\u00f5es e t\u00f3picos tem\u00e1ticos, organizando as vozes dispersas da popula\u00e7\u00e3o em clusters interpret\u00e1veis.</p> <p>Cada manifesta\u00e7\u00e3o ser\u00e1 analisada pelo modelo de forma contextual, considerando que uma mesma manifesta\u00e7\u00e3o pode abranger m\u00faltiplos temas. Assim, o sistema n\u00e3o apenas atribui um cluster principal, mas tamb\u00e9m estima o grau de pertencimento (em porcentagem) a outros temas correlatos, oferecendo uma vis\u00e3o mais precisa da multiplicidade de sentidos e inten\u00e7\u00f5es contida nas mensagens.</p> <p>Durante o desenvolvimento conceitual, diferentes p\u00fablicos-alvo foram considerados, jornalistas, pesquisadores e entidades sociais, mas a an\u00e1lise do problema (refletida no Fishbone Diagram) evidenciou que os gestores p\u00fablicos s\u00e3o o p\u00fablico que mais sofre com a falta de mecanismos anal\u00edticos para compreender manifesta\u00e7\u00f5es cidad\u00e3s. A incapacidade de identificar padr\u00f5es entre dados textuais dispersos leva \u00e0 formula\u00e7\u00e3o de pol\u00edticas baseadas em percep\u00e7\u00f5es parciais e n\u00e3o em tend\u00eancias reais.</p> <p>Neste contexto, o Vozes em Rede prop\u00f5e um avan\u00e7o t\u00e9cnico e social: criar uma ferramenta de an\u00e1lise automatizada de manifesta\u00e7\u00f5es, apoiada em clusteriza\u00e7\u00e3o sem\u00e2ntica e m\u00e9tricas de similaridade contextual, que traduza dados desestruturados em insights tem\u00e1ticos concretos. Por \u201cmanifesta\u00e7\u00f5es\u201d, entende-se qualquer forma de express\u00e3o cidad\u00e3, desde relatos, den\u00fancias e coment\u00e1rios em canais oficiais at\u00e9 discuss\u00f5es em ambientes digitais.</p> <p>Em s\u00edntese, a vis\u00e3o do produto \u00e9 oferecer um modelo de intelig\u00eancia coletiva aplicada \u00e0 gest\u00e3o p\u00fablica, capaz de transformar o ru\u00eddo das redes e plataformas em mapas tem\u00e1ticos de demandas sociais, evidenciando com precis\u00e3o o que a sociedade comunica, onde est\u00e3o as principais tens\u00f5es e quais temas emergem com maior relev\u00e2ncia.</p>"}]}